
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>How it works &#8212; automatminer 2019.03.27_beta documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
          

          <div class="body" role="main">
            
  <style> .red {color:#aa0060; font-weight:bold; font-size:16px} </style><p><span class="red">WARNING! These docs and examples are a work in progress. Read and use at your own risk!`</span></p>
<a class="reference internal image-reference" href="_images/logo.svg"><div align="center" class="align-center"><img alt="server" src="_images/logo.svg" width="600px" /></div>
</a>
<p>Automatminer is a tool for <em>automatically</em> creating <strong>complete</strong> machine learning pipelines for materials science, including automatic featurization with <a class="reference external" href="https://github.com/hackingmaterials/matminer">matminer</a>, feature reduction, and an AutoML backend. Put in a materials dataset, get out a machine that predicts materials properties.</p>
<div class="section" id="how-it-works">
<h1>How it works<a class="headerlink" href="#how-it-works" title="Permalink to this headline">¶</a></h1>
<p>Automatminer automatically decorates a dataset using hundreds of descriptor techniques from matminer’s descriptor library, picks the most useful features for learning, and runs a separate AutoML pipeline using TPOT. Once a pipeline has been fit, it can be examined with skater’s interpretability tools, summarized in a text file, saved to disk, or used to make new predictions.</p>
<img alt="server" class="align-center" src="_images/automatminer_big.jpg" />
<p>Here’s an example of training on known data, and extending the model to out of sample data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">automatminer.pipeline</span> <span class="kn">import</span> <span class="n">MatPipe</span>

<span class="c1"># Fit a pipeline to training data to predict band gap</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">MatPipe</span><span class="p">()</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="s2">&quot;band gap&quot;</span><span class="p">)</span>

<span class="c1"># Predict bandgap of some unknown materials</span>
<span class="n">predicted_df</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">unknown_df</span><span class="p">,</span> <span class="s2">&quot;band gap&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Or, run a (relatively) rigorous nested cross validation benchmark on a known dataset, and then compare the results against your own ML models:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">automatminer.pipeline</span> <span class="kn">import</span> <span class="n">MatPipe</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">MatPipe</span><span class="p">()</span>
<span class="n">predictions_per_fold</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s2">&quot;bulk modulus&quot;</span><span class="p">,</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="scope">
<h1>Scope<a class="headerlink" href="#scope" title="Permalink to this headline">¶</a></h1>
<div class="section" id="automatminer-can-work-with-many-kinds-of-data">
<h2>Automatminer can work with many kinds of data:<a class="headerlink" href="#automatminer-can-work-with-many-kinds-of-data" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>both computational and experimental data</li>
<li>small (~100 samples) to moderate (~100k samples) sized datasets</li>
<li>crystalline datasets</li>
<li>composition-only (i.e., unknown phases) datasets</li>
<li>datasets containing electronic bandstructures or density of states</li>
</ul>
</div>
<div class="section" id="many-kinds-of-target-properties">
<h2>Many kinds of target properties:<a class="headerlink" href="#many-kinds-of-target-properties" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>electronic</li>
<li>mechanical</li>
<li>thermodynamic</li>
<li>any other kind of property</li>
</ul>
</div>
<div class="section" id="and-many-featurization-descriptor-techniques">
<h2>And many featurization (descriptor) techniques:<a class="headerlink" href="#and-many-featurization-descriptor-techniques" title="Permalink to this headline">¶</a></h2>
<p>See <a class="reference external" href="https://hackingmaterials.github.io/matminer/featurizer_summary.html">matminer’s Table of Featurizers</a> for a full (and growing) list.</p>
</div>
</div>
<div class="section" id="installation">
<h1>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h1>
<p>Install from Pypi:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install automatminer
</pre></div>
</div>
<p>Clone latest code from github</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/hackingmaterials/automatminer
<span class="nb">cd</span> automatminer
pip install -e .
</pre></div>
</div>
</div>
<div class="section" id="full-code-examples">
<h1>Full Code Examples<a class="headerlink" href="#full-code-examples" title="Permalink to this headline">¶</a></h1>
<p>We are now going to walk through how to create a MatPipe using the default
configurations and the elastic_tensor_2015 dataset. We will then use this
MatPipe to benchmark the target property K_VRH and we will use our results
to determine the mean squared error. Buckle up!</p>
<div class="section" id="setting-up-the-dataframe">
<h2>Setting up the Dataframe<a class="headerlink" href="#setting-up-the-dataframe" title="Permalink to this headline">¶</a></h2>
<p>We will use the matminer function load_dataset to give us access to the
elastic_tensor_2015 dataset. The result is a Pandas dataframe.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matminer.datasets.dataset_retrieval</span> <span class="kn">import</span> <span class="n">load_dataset</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;elastic_tensor_2015&quot;</span><span class="p">)</span> <span class="c1">#Loads in Pandas dataset</span>
</pre></div>
</div>
<p>Next, we will use get_preset_config to use different pre-built configurations
for a MatPipe. The options include production, default, robust, and debug.
Specific details about each config can be seen in <a class="reference external" href="api/automatminer.get_preset_config.html">presets.py</a>. In this example, we will be using
the debug config for a short program runtime. Of course, you do not need to use
a preset configuration. Simply use the <a class="reference external" href="api/automatminer.MatPipe.html">MatPipe</a>
functions to choose your own adaptor. After this step, we will pass in the parameter
as an argument of <a class="reference external" href="api/automatminer.MatPipe.html">MatPipe</a> to get a MatPipe
object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">automatminer.presets</span> <span class="kn">import</span> <span class="n">get_preset_config</span>
<span class="kn">from</span> <span class="nn">automatminer.pipeline</span> <span class="kn">import</span> <span class="n">MatPipe</span>

<span class="c1"># Get preset configurations for debug. The debug configuration allows</span>
<span class="c1"># for rapid testing while the other configurations are more useful for</span>
<span class="c1"># real-world applications.</span>
<span class="n">debug_config</span> <span class="o">=</span> <span class="n">get_preset_config</span><span class="p">(</span><span class="s2">&quot;debug&quot;</span><span class="p">)</span>
<span class="c1"># Create a MatPipe using our configuration.</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">MatPipe</span><span class="p">(</span><span class="o">**</span><span class="n">debug_config</span><span class="p">)</span>
</pre></div>
</div>
<p>The preset automatminer uses pre-defined column names ‘composition’ and ‘structure’
to find the composition and structure columns. You can easily fix this by renaming
your respective columns to the correct names.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Rename the appropriate dataframe columns to create a dataframe that</span>
<span class="c1"># can be passed into our automatminer functions.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;formula&quot;</span><span class="p">:</span> <span class="s2">&quot;composition&quot;</span><span class="p">})[[</span><span class="s2">&quot;composition&quot;</span><span class="p">,</span> <span class="s2">&quot;structure&quot;</span><span class="p">,</span> <span class="s2">&quot;K_VRH&quot;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="section" id="benchmarking-automatminer-s-performance">
<h2>Benchmarking automatminer’s performance<a class="headerlink" href="#benchmarking-automatminer-s-performance" title="Permalink to this headline">¶</a></h2>
<p>In this example, we are performing a machine learning benchmark using MatPipe
in order to see how well our MatPipe can predict a certain target property.
The target property we will be benchmarking in this example is K_VRH. Keep in
mind that benchmarking requires a KFold object since benchmarks are run with
nested cross validation. But why nested cross validation?</p>
</div>
<div class="section" id="nested-cv-for-benchmarking">
<h2>Nested CV for benchmarking<a class="headerlink" href="#nested-cv-for-benchmarking" title="Permalink to this headline">¶</a></h2>
<p>Reporting a regular cross validation score is fine, if you are not tuning the
hyperparameters of your model.</p>
<a class="reference internal image-reference" href="_images/cv_single.png"><img alt="cv_overfit" class="align-center" src="_images/cv_single.png" style="width: 70%;" /></a>
<p>But if the model’s hyperparameters are adjusted
to improve its CV score, reporting the CV score as the generalization error is
incorrect, because the model may have been overfit to the training dataset.</p>
<a class="reference internal image-reference" href="_images/cv_overfit.png"><img alt="cv_overfit" class="align-center" src="_images/cv_overfit.png" style="width: 70%;" /></a>
<p>Using a hold out test set is a better - in this procedure, all training and
validation is done without knowledge of the final test set, then the
generalization error is estimated from the prediction error on the test set.
However, the choice of test set may result in over- or under-representing
your models generalization error.</p>
<img alt="cv_overfit" class="align-center" src="_images/cv_holdout.png" />
<p>Furthermore, if your model’s hyperparameters
are adjusted based on the test score (and not only the validation score), the
model will also be overfit to the test set.</p>
<p>Nested CV mitigates these issues by repeating the following hold-out test procedure k times:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Split data into train/validation and hold out test.</li>
<li>Give only the train/validation data to the model and allow it to optimize hyperparameters using any method it chooses</li>
<li>Once the model’s hyperparameters are set, predict the hold out test set and report that as the generalization error.</li>
</ol>
</div></blockquote>
<p>1-3 are repeated for each of k folds in the Nested CV, ensuring every sample in the dataset is tested once.
This mitigates the performance of the benchmark based on the choice of test set and also better estimates the generalization error
than a single validation/test split would.</p>
<img alt="cv_overfit" class="align-center" src="_images/cv_nested.png" />
<p>tl;dr: <strong>“A nested CV procedure provides an almost unbiased estimate of the true error.”</strong> – Varma and Simon, 2006 (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/16504092">10.1186/1471-2105-7-91</a>)</p>
</div>
<div class="section" id="setting-up-the-benchmark">
<h2>Setting up the benchmark<a class="headerlink" href="#setting-up-the-benchmark" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">MatPipe benchmarks with a nested cross validation, meaning it makes</span>
<span class="sd">k validation/test splits, where all model selection is done on the train</span>
<span class="sd">/validation set (a typical CV). When the model is done validating, it is</span>
<span class="sd">used to predict the previously unseen test set data.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> <span class="c1">#We will use a 5-Fold object.</span>
<span class="n">predicted_folds</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s2">&quot;K_VRH&quot;</span><span class="p">,</span> <span class="n">kfold</span><span class="p">)</span>
</pre></div>
</div>
<p>The result of pipe.benchmark() will be a list of dataframes (one for each
nested CV fold). Each new dataframe has the predicted results
stored in a column called the property name combined with ” predicted”. In this
example, it will be stored in “K_VRH predicted.”</p>
</div>
<div class="section" id="calculating-mse">
<h2>Calculating MSE<a class="headerlink" href="#calculating-mse" title="Permalink to this headline">¶</a></h2>
<p>For each test fold in our nested CV, we can calculate the prediction error.</p>
<p>Next, we can use the sklearn package to calculate a wide variety of metrics on
our predictions. In this case, we want the mean squared error so we will use that
function.</p>
<p>Finally, we calculate the mean mse across our test sets.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics.regression</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="c1"># A list to hold our mse scores for each test fold</span>
<span class="n">mses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Calculating mse for each test fold</span>
<span class="k">for</span> <span class="n">predicted</span> <span class="ow">in</span> <span class="n">predicted_folds</span><span class="p">:</span>
    <span class="c1"># Save the actual K_VRH Series to y_true.</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">predicted</span><span class="p">[</span><span class="s2">&quot;K_VRH&quot;</span><span class="p">]</span>
    <span class="c1"># Save the predicted K_VRH Series to y_test.</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">predicted</span><span class="p">[</span><span class="s2">&quot;K_VRH predicted&quot;</span><span class="p">]</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="n">mses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">mses</span><span class="p">)</span>
</pre></div>
</div>
<p>And voilà, we are done! We have successfully loaded in a dataset, benchmarked a test property
using a MatPipe with ‘debug’ configs, and then ran an analysis on our results by calculating
MSE for each fold of a nested CV.</p>
</div>
</div>
<div class="section" id="citing-automatminer">
<h1>Citing automatminer<a class="headerlink" href="#citing-automatminer" title="Permalink to this headline">¶</a></h1>
<p>We are in the process of writing a paper for automatminer. In the meantime, please use the citation given in the <a class="reference external" href="https://github.com/hackingmaterials/matminer">matminer repo</a>.</p>
</div>
<div class="section" id="contributing">
<h1>Contributing<a class="headerlink" href="#contributing" title="Permalink to this headline">¶</a></h1>
<p>Interested in contributing? See our <a class="reference external" href="https://github.com/hackingmaterials/automatminer/blob/master/CONTRIBUTING.md">contribution guidelines</a> and make a pull request! Please submit questions, issues/bug reports, and all other communication through the  <a class="reference external" href="https://groups.google.com/forum/#!forum/matminer">matminer Google Group</a>.</p>
</div>
<div class="section" id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></li>
<li><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></li>
<li><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></li>
<li><a class="reference internal" href="directory.html#directory"><span class="std std-ref">Python API</span></a></li>
</ul>
</div>


          </div>
          
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Alex Dunn.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>